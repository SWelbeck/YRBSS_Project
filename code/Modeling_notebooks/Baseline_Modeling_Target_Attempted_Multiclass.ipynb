{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Ensemble Methods - Target: Attempted Suicide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:37:48.459019Z",
     "start_time": "2021-01-07T15:37:46.191693Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 150, 'display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:37:49.098824Z",
     "start_time": "2021-01-07T15:37:48.462061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>raceeth</th>\n",
       "      <th>How old are you</th>\n",
       "      <th>What is your sex</th>\n",
       "      <th>In what grade are you</th>\n",
       "      <th>How tall are you</th>\n",
       "      <th>How much do you weigh</th>\n",
       "      <th>Seat belt use</th>\n",
       "      <th>Riding with a drinking driver</th>\n",
       "      <th>Drinking and driving</th>\n",
       "      <th>Weapon carrying</th>\n",
       "      <th>Weapon carrying at school</th>\n",
       "      <th>Safety concerns at school</th>\n",
       "      <th>Threatened at school</th>\n",
       "      <th>Physical fighting</th>\n",
       "      <th>Physical fighting at school</th>\n",
       "      <th>Forced sexual intercourse</th>\n",
       "      <th>Bullying at school</th>\n",
       "      <th>Electronic bullying</th>\n",
       "      <th>Sad or hopeless</th>\n",
       "      <th>Considered suicide</th>\n",
       "      <th>Made a suicide plan</th>\n",
       "      <th>Attempted suicide</th>\n",
       "      <th>Injurious suicide attempt</th>\n",
       "      <th>Ever cigarette use</th>\n",
       "      <th>Initiation of cigarette smoking</th>\n",
       "      <th>Current cigarette use</th>\n",
       "      <th>Current smokeless tobacco use</th>\n",
       "      <th>Current cigar use</th>\n",
       "      <th>Initiation of alcohol use</th>\n",
       "      <th>Current alcohol use</th>\n",
       "      <th>Source of alcohol</th>\n",
       "      <th>Ever marijuana use</th>\n",
       "      <th>Initiation of marijuana use</th>\n",
       "      <th>Current marijuana use</th>\n",
       "      <th>Ever steroid use</th>\n",
       "      <th>Illegal injected drug use</th>\n",
       "      <th>Illegal drugs at school</th>\n",
       "      <th>Ever sexual intercourse</th>\n",
       "      <th>Sex before 13 years</th>\n",
       "      <th>Multiple sex partners</th>\n",
       "      <th>Current sexual activity</th>\n",
       "      <th>Alcohol/drugs and sex</th>\n",
       "      <th>Condom use</th>\n",
       "      <th>Birth control pill use</th>\n",
       "      <th>Perception of weight</th>\n",
       "      <th>Weight loss</th>\n",
       "      <th>Television watching</th>\n",
       "      <th>Computer use</th>\n",
       "      <th>HIV testing</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Sleep</th>\n",
       "      <th>Ever used LSD</th>\n",
       "      <th>BMIPCT</th>\n",
       "      <th>weight</th>\n",
       "      <th>stratum</th>\n",
       "      <th>psu</th>\n",
       "      <th>Has used hard drugs</th>\n",
       "      <th>healthy_eating</th>\n",
       "      <th>regular_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>54.89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.882141</td>\n",
       "      <td>1.6659</td>\n",
       "      <td>213.0</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>53.98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.232194</td>\n",
       "      <td>1.3851</td>\n",
       "      <td>213.0</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>43.09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590171</td>\n",
       "      <td>1.4958</td>\n",
       "      <td>213.0</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>68.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>69.786634</td>\n",
       "      <td>1.7114</td>\n",
       "      <td>213.0</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>58.97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.739994</td>\n",
       "      <td>1.6659</td>\n",
       "      <td>213.0</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR  raceeth  How old are you  What is your sex  In what grade are you  \\\n",
       "0  2019.0      7.0              5.0               2.0                    2.0   \n",
       "1  2019.0      8.0              4.0               2.0                    2.0   \n",
       "2  2019.0      8.0              4.0               1.0                    2.0   \n",
       "3  2019.0      5.0              4.0               2.0                    2.0   \n",
       "4  2019.0      6.0              5.0               2.0                    2.0   \n",
       "\n",
       "   How tall are you  How much do you weigh  Seat belt use  \\\n",
       "0              1.63                  54.89            4.0   \n",
       "1              1.60                  53.98            5.0   \n",
       "2              1.68                  43.09            4.0   \n",
       "3              1.78                  68.95            4.0   \n",
       "4              1.78                  58.97            4.0   \n",
       "\n",
       "   Riding with a drinking driver  Drinking and driving  Weapon carrying  \\\n",
       "0                            1.0                   2.0              1.0   \n",
       "1                            2.0                   2.0              1.0   \n",
       "2                            1.0                   2.0              1.0   \n",
       "3                            1.0                   1.0              1.0   \n",
       "4                            1.0                   1.0              1.0   \n",
       "\n",
       "   Weapon carrying at school  Safety concerns at school  Threatened at school  \\\n",
       "0                        1.0                        1.0                   1.0   \n",
       "1                        1.0                        1.0                   1.0   \n",
       "2                        1.0                        1.0                   1.0   \n",
       "3                        1.0                        1.0                   1.0   \n",
       "4                        1.0                        1.0                   1.0   \n",
       "\n",
       "   Physical fighting  Physical fighting at school  Forced sexual intercourse  \\\n",
       "0                1.0                          1.0                        2.0   \n",
       "1                1.0                          1.0                        2.0   \n",
       "2                1.0                          1.0                        2.0   \n",
       "3                1.0                          1.0                        2.0   \n",
       "4                1.0                          1.0                        2.0   \n",
       "\n",
       "   Bullying at school  Electronic bullying  Sad or hopeless  \\\n",
       "0                 2.0                  2.0              2.0   \n",
       "1                 1.0                  2.0              2.0   \n",
       "2                 2.0                  2.0              2.0   \n",
       "3                 2.0                  2.0              1.0   \n",
       "4                 2.0                  2.0              2.0   \n",
       "\n",
       "   Considered suicide  Made a suicide plan  Attempted suicide  \\\n",
       "0                 2.0                  2.0                1.0   \n",
       "1                 2.0                  2.0                1.0   \n",
       "2                 2.0                  2.0                1.0   \n",
       "3                 2.0                  2.0                1.0   \n",
       "4                 2.0                  2.0                1.0   \n",
       "\n",
       "   Injurious suicide attempt  Ever cigarette use  \\\n",
       "0                        1.0                 2.0   \n",
       "1                        1.0                 2.0   \n",
       "2                        1.0                 2.0   \n",
       "3                        1.0                 1.0   \n",
       "4                        1.0                 2.0   \n",
       "\n",
       "   Initiation of cigarette smoking  Current cigarette use  \\\n",
       "0                              1.0                    1.0   \n",
       "1                              1.0                    1.0   \n",
       "2                              1.0                    1.0   \n",
       "3                              4.0                    3.0   \n",
       "4                              1.0                    1.0   \n",
       "\n",
       "   Current smokeless tobacco use  Current cigar use  \\\n",
       "0                            1.0                1.0   \n",
       "1                            1.0                1.0   \n",
       "2                            1.0                1.0   \n",
       "3                            1.0                1.0   \n",
       "4                            1.0                1.0   \n",
       "\n",
       "   Initiation of alcohol use  Current alcohol use  Source of alcohol  \\\n",
       "0                        1.0                  1.0                1.0   \n",
       "1                        1.0                  1.0                1.0   \n",
       "2                        1.0                  1.0                1.0   \n",
       "3                        5.0                  3.0                7.0   \n",
       "4                        1.0                  1.0                1.0   \n",
       "\n",
       "   Ever marijuana use  Initiation of marijuana use  Current marijuana use  \\\n",
       "0                 1.0                          1.0                    1.0   \n",
       "1                 2.0                          5.0                    1.0   \n",
       "2                 1.0                          1.0                    1.0   \n",
       "3                 7.0                          4.0                    6.0   \n",
       "4                 1.0                          1.0                    1.0   \n",
       "\n",
       "   Ever steroid use  Illegal injected drug use  Illegal drugs at school  \\\n",
       "0               1.0                        1.0                      1.0   \n",
       "1               1.0                        1.0                      2.0   \n",
       "2               1.0                        1.0                      2.0   \n",
       "3               1.0                        1.0                      1.0   \n",
       "4               1.0                        1.0                      2.0   \n",
       "\n",
       "   Ever sexual intercourse  Sex before 13 years  Multiple sex partners  \\\n",
       "0                      2.0                  1.0                    1.0   \n",
       "1                      2.0                  1.0                    1.0   \n",
       "2                      2.0                  1.0                    1.0   \n",
       "3                      2.0                  1.0                    1.0   \n",
       "4                      2.0                  1.0                    1.0   \n",
       "\n",
       "   Current sexual activity  Alcohol/drugs and sex  Condom use  \\\n",
       "0                      1.0                    1.0         1.0   \n",
       "1                      1.0                    1.0         1.0   \n",
       "2                      1.0                    1.0         1.0   \n",
       "3                      1.0                    1.0         1.0   \n",
       "4                      1.0                    1.0         1.0   \n",
       "\n",
       "   Birth control pill use  Perception of weight  Weight loss  \\\n",
       "0                     1.0                   3.0          3.0   \n",
       "1                     1.0                   3.0          1.0   \n",
       "2                     1.0                   2.0          4.0   \n",
       "3                     1.0                   3.0          3.0   \n",
       "4                     1.0                   3.0          4.0   \n",
       "\n",
       "   Television watching  Computer use  HIV testing  Asthma  Sleep  \\\n",
       "0                  2.0           5.0          2.0     2.0    4.0   \n",
       "1                  3.0           3.0          2.0     2.0    4.0   \n",
       "2                  2.0           4.0          3.0     2.0    5.0   \n",
       "3                  7.0           7.0          2.0     3.0    4.0   \n",
       "4                  1.0           4.0          2.0     2.0    2.0   \n",
       "\n",
       "   Ever used LSD     BMIPCT  weight  stratum      psu  Has used hard drugs  \\\n",
       "0            1.0  46.882141  1.6659    213.0  57923.0                  0.0   \n",
       "1            1.0  62.232194  1.3851    213.0  57923.0                  0.0   \n",
       "2            1.0   0.590171  1.4958    213.0  57923.0                  0.0   \n",
       "3            3.0  69.786634  1.7114    213.0  57923.0                  1.0   \n",
       "4            1.0  16.739994  1.6659    213.0  57923.0                  0.0   \n",
       "\n",
       "   healthy_eating  regular_activity  \n",
       "0             1.0               1.0  \n",
       "1             1.0               1.0  \n",
       "2             1.0               0.0  \n",
       "3             1.0               0.0  \n",
       "4             1.0               0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data and split data to be used in the models\n",
    "df = pd.read_csv('modeling_dataset.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:37:49.116115Z",
     "start_time": "2021-01-07T15:37:49.106469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create matrix of features\n",
    "X = df.drop('Attempted suicide', axis = 1) # grabs everything else but target\n",
    "\n",
    "# Create target variable\n",
    "y = df['Attempted suicide'] # y is the column we're trying to predict\n",
    "\n",
    "# Create a list of the features being used in the \n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:37:51.005607Z",
     "start_time": "2021-01-07T15:37:50.760299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use x and y variables to split the training data into train and test set then scale that data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:37:59.405161Z",
     "start_time": "2021-01-07T15:37:59.401088Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:38:00.147889Z",
     "start_time": "2021-01-07T15:38:00.142869Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:41:35.777543Z",
     "start_time": "2021-01-07T15:38:00.982069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9350091802297837\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_preds = knn.predict(X_test)\n",
    "\n",
    "knn_f1 = metrics.f1_score(y_test, knn_preds, average='weighted')\n",
    "\n",
    "\n",
    "print(knn_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Logistic Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:41:47.835246Z",
     "start_time": "2021-01-07T15:41:47.742412Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:41:48.969150Z",
     "start_time": "2021-01-07T15:41:48.923871Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:41:54.772767Z",
     "start_time": "2021-01-07T15:41:50.529451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:41:54.891431Z",
     "start_time": "2021-01-07T15:41:54.779481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411999749651749\n"
     ]
    }
   ],
   "source": [
    "lr_preds = lr.predict(X_test)\n",
    "\n",
    "lr_f1 = metrics.f1_score(y_test, lr_preds, average='weighted')\n",
    "\n",
    "print(lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:42:04.226772Z",
     "start_time": "2021-01-07T15:42:04.208412Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:42:05.231471Z",
     "start_time": "2021-01-07T15:42:04.943516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.930768918387795\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "dtc_preds  = dtc.predict(X_test)\n",
    "\n",
    "dtc_f1 = metrics.f1_score(y_test, dtc_preds, average='weighted')\n",
    "\n",
    "print(dtc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine three models using Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:56:44.314953Z",
     "start_time": "2021-01-07T15:56:44.235491Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the estimators, we must provide a list of tuples. The first value in the tuple is is the name given to the model/estimator in the second value. SKlearn requires this because there is additional functionality where you can access information about the specific models, so you need to name the models to access them later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:05:53.085758Z",
     "start_time": "2021-01-07T16:02:09.687452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9421721640119471\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('logreg', lr), ('knneighbors', knn), ('decisiontree', dtc)], \n",
    "                voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "vc_preds = voting_clf.predict(X_test)\n",
    "\n",
    "vc_f1 = metrics.f1_score(y_test, vc_preds, average='weighted')\n",
    "\n",
    "print(vc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a voting classifier with multiple Logistic regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:06.101029Z",
     "start_time": "2021-01-07T16:07:43.313481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "C_param_range = [0.001,0.01,0.1,1,10]\n",
    "titles = ['lr_0_001', 'lr_0_01', 'lr_0_1', 'lr_1', 'lr_10']\n",
    "\n",
    "params = dict(zip(titles, C_param_range)) \n",
    "models = {}\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','F1'])\n",
    "table['C_parameter'] = C_param_range\n",
    "j = 0\n",
    "\n",
    "for k , v  in params.items():\n",
    "    \n",
    "    # Create model using different value for c  \n",
    "    lr = LogisticRegression(penalty = 'l2', C = v, random_state = 1, class_weight='balanced')\n",
    "    \n",
    "    #save the model to a dictionary to use later in our voting classifiers\n",
    "    models[k]= lr\n",
    "    \n",
    "    #the steps below this point are unnecessary in order to create a voting classifier, \n",
    "    #but it is easy to fit the model and see how performance changes for different levels of regularization\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_preds = lr.predict(X_test)\n",
    "\n",
    "    # Saving accuracy score in table\n",
    "    table.iloc[j,1] = metrics.f1_score(y_test, y_preds, average='weighted')\n",
    "    j += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:06.194073Z",
     "start_time": "2021-01-07T16:08:06.107264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.941635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.942353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.941711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.941564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter        F1\n",
       "0        0.001  0.941635\n",
       "1        0.010  0.942353\n",
       "2        0.100  0.941711\n",
       "3        1.000    0.9412\n",
       "4       10.000  0.941564"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review performance for different levels of C\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:06.412353Z",
     "start_time": "2021-01-07T16:08:06.263793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lr_0_001',\n",
       "  LogisticRegression(C=0.001, class_weight='balanced', random_state=1)),\n",
       " ('lr_0_01',\n",
       "  LogisticRegression(C=0.01, class_weight='balanced', random_state=1)),\n",
       " ('lr_0_1',\n",
       "  LogisticRegression(C=0.1, class_weight='balanced', random_state=1)),\n",
       " ('lr_1', LogisticRegression(C=1, class_weight='balanced', random_state=1)),\n",
       " ('lr_10', LogisticRegression(C=10, class_weight='balanced', random_state=1))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invesitgate the models D=dictionary\n",
    "list(models.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have programmatically created multiple logistic regression models, let's use them in an ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:29.812600Z",
     "start_time": "2021-01-07T16:08:06.424392Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9418343691647996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr_voting = VotingClassifier(estimators=list(models.items()), \n",
    "                              voting='hard')\n",
    "\n",
    "lr_voting.fit(X_train, y_train)\n",
    "\n",
    "lrv_preds = lr_voting.predict(X_test)\n",
    "\n",
    "lrv_f1 = metrics.f1_score(y_test, lrv_preds, average='weighted')\n",
    "\n",
    "print(lrv_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Bagging Classifier for a Logistic Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:10:30.094600Z",
     "start_time": "2021-01-07T16:10:30.069030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40161, 59)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:10:31.528176Z",
     "start_time": "2021-01-07T16:10:31.487732Z"
    }
   },
   "outputs": [],
   "source": [
    "bc_lr = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(random_state = 1, class_weight='balanced'), \n",
    "            n_estimators= 100,\n",
    "            max_samples= 0.8,\n",
    "            max_features= 6,\n",
    "            oob_score= True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:11:40.034802Z",
     "start_time": "2021-01-07T16:10:32.657996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                    random_state=1),\n",
       "                  max_features=6, max_samples=0.8, n_estimators=100,\n",
       "                  oob_score=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_lr.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:11:40.052128Z",
     "start_time": "2021-01-07T16:11:40.038223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922711087871318"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the oob_score to get some idea of how the model performs on a validation set\n",
    "\n",
    "bc_lr.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:16:20.792070Z",
     "start_time": "2021-01-07T16:16:20.338806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9273726459956455\n"
     ]
    }
   ],
   "source": [
    "# See how the model performs on the test set\n",
    "\n",
    "bc_lr_preds = bc_lr.predict(X_test)\n",
    "\n",
    "bc_lr_f1 = metrics.f1_score(y_test, bc_lr_preds, average='weighted')\n",
    "\n",
    "print(bc_lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What is the difference in the `VotingClassifier` algorithm and the `BaggingClassifier` algorithm?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the difference between a BaggingClassifier that uses a decision tree as the base estimator and a Random Forest Classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest classifier will take a sample of features at each node, where as a bagging classifier will take a sample of features at to use for the whole model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:16:33.210679Z",
     "start_time": "2021-01-07T16:16:33.191749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the classifier using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state = 1, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:16:34.210998Z",
     "start_time": "2021-01-07T16:16:34.194283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's look at all the different default features\n",
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:53.909269Z",
     "start_time": "2021-01-07T16:16:35.186923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model to the training data\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:56.166967Z",
     "start_time": "2021-01-07T16:17:53.920940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.9518437458926547\n"
     ]
    }
   ],
   "source": [
    "#use the fitted model to predict on the test data\n",
    "rfc_preds = rfc.predict(X_test)\n",
    "\n",
    "rfc_f1 = metrics.f1_score(y_test, rfc_preds, average='weighted')\n",
    "\n",
    "# checking accuracy on the test data\n",
    "print('Test F1 score: ', rfc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Change the parameters and see whether you can improve the performance of the model***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridsearchCV with Random Forest\n",
    "\n",
    "Let's use grid search to identify the best tuning parameters to use for a random forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of all the parameters you want to tune\n",
    "param_grid = { \n",
    "    'n_estimators': [100,300,500,700,1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(2,10)),\n",
    "    'max_features': list(range(3,7))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a grid search object and fit it to the data\n",
    "\n",
    "grid_tree=GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify the best params \n",
    "\n",
    "\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_tree.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_tree.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_tree.best_estimator_)\n",
    "#Identify the best score during fitting with cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = grid_tree.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model F1, how often is the classifier correct?\n",
    "print(\"F1:\",metrics.f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Grid Search and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:03:07.174691Z",
     "start_time": "2020-12-21T16:03:02.760981Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:04:09.185312Z",
     "start_time": "2020-12-21T16:04:09.003833Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:04:09.984355Z",
     "start_time": "2020-12-21T16:04:09.916202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Drop nulls in embarked\n",
    "df.dropna(subset=['embarked','embark_town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:04:11.117377Z",
     "start_time": "2020-12-21T16:04:11.113486Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['pclass', 'sex','parch', \n",
    "       'embarked', 'class', 'who', 'adult_male', 'embark_town']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:04:12.093436Z",
     "start_time": "2020-12-21T16:04:12.052798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fit the \n",
    "le = LabelEncoder()\n",
    "df.loc[:,cols] = df.loc[:,cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:04:12.783992Z",
     "start_time": "2020-12-21T16:04:12.768311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define x and y \n",
    "y = df['survived']\n",
    "X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
    "       'embarked', 'class', 'who', 'adult_male', 'embark_town']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:05:39.072223Z",
     "start_time": "2020-12-21T16:05:38.950827Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex   age  sibsp  parch     fare  embarked  class  who  adult_male  \\\n",
       "0       2    1  22.0      1      0   7.2500         2      2    1           1   \n",
       "1       0    0  38.0      1      0  71.2833         0      0    2           0   \n",
       "2       2    0  26.0      0      0   7.9250         2      2    2           0   \n",
       "3       0    0  35.0      1      0  53.1000         2      0    2           0   \n",
       "4       2    1  35.0      0      0   8.0500         2      2    1           1   \n",
       "\n",
       "   embark_town  \n",
       "0            2  \n",
       "1            0  \n",
       "2            2  \n",
       "3            2  \n",
       "4            2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can split the data using stratify to make sure we can get an even split of classes in the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:08:21.318602Z",
     "start_time": "2020-12-21T16:08:21.222216Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split X and y with even class distributions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:13:51.688779Z",
     "start_time": "2020-12-21T16:13:51.495349Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrawelbeck/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "#Impute age using the training mean\n",
    "mean_age = X_train.age.mean()\n",
    "X_train['age'].fillna(mean_age, inplace=True)\n",
    "X_test['age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:13:57.008114Z",
     "start_time": "2020-12-21T16:13:56.936226Z"
    }
   },
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = pd.DataFrame(ss.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(ss.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:13:58.227262Z",
     "start_time": "2020-12-21T16:13:57.454060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:14:00.321984Z",
     "start_time": "2020-12-21T16:13:58.237694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8002954791687186"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now with cross validation search\n",
    "val = cross_val_score(RandomForestClassifier(random_state=42),X_train,y_train,cv=5)\n",
    "val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:16:04.701672Z",
     "start_time": "2020-12-21T16:16:04.659136Z"
    }
   },
   "outputs": [],
   "source": [
    "#If you were to line up all the possible values of one and of the other, they create a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:16:05.915707Z",
     "start_time": "2020-12-21T16:16:05.860004Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
    "    \"max_features\": [None,4,5,6,9,10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 5, 6],\n",
    "    \"n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:16:39.854385Z",
     "start_time": "2020-12-21T16:16:39.735991Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_grid = RandomForestClassifier(random_state=42)\n",
    "gridsearch = GridSearchCV(rf_grid, rf_param_grid, cv=5, return_train_score=True, n_jobs=-1, verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T17:10:48.441677Z",
     "start_time": "2020-12-21T16:16:41.979848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8704 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12160 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14104 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 27.3min\n",
      "[Parallel(n_jobs=-1)]: Done 18424 tasks      | elapsed: 33.9min\n",
      "[Parallel(n_jobs=-1)]: Done 20800 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 23320 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=-1)]: Done 25984 tasks      | elapsed: 49.6min\n",
      "[Parallel(n_jobs=-1)]: Done 28792 tasks      | elapsed: 53.1min\n",
      "[Parallel(n_jobs=-1)]: Done 29700 out of 29700 | elapsed: 54.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
       "                         'max_features': [None, 4, 5, 6, 9, 10],\n",
       "                         'min_samples_leaf': [1, 2, 3, 5, 6],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 30, 100]},\n",
       "             return_train_score=True, verbose=-1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T18:27:37.723947Z",
     "start_time": "2020-12-21T18:27:37.593114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 84.11%\n",
      "\n",
      "Optimal Parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 5, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "Best Model: RandomForestClassifier(max_depth=10, max_features=5, min_samples_leaf=3,\n",
      "                       min_samples_split=10, n_estimators=10, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {:.4}%\".format(gridsearch.best_score_ * 100))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(gridsearch.best_params_))\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(\"Best Model: {}\".format(gridsearch.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T18:27:40.821576Z",
     "start_time": "2020-12-21T18:27:40.691634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T18:27:41.400784Z",
     "start_time": "2020-12-21T18:27:41.394539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29700"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV * Number of params to search\n",
    "5*2*11*6*3*5*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "# Split X and y with even class distributions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)\n",
    "\n",
    "#Impute age using the training mean\n",
    "mean_age = X_train.age.mean()\n",
    "X_train['age'].fillna(mean_age, inplace=True)\n",
    "X_test['age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our pipeline by passing a list of tuples with each class and its name in a string\n",
    "pipeline1 = Pipeline([\n",
    "                    ('ss',StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(random_state=42))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the training data to pipeline\n",
    "pipeline1.fit(X_train,y_train)\n",
    "\n",
    "# Print the accuracy on test set\n",
    "pipeline1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "                    ('ss',StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(random_state=42))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the params, but we add a rf__ to each parameter to let it know its on the rf part of the pipeline\n",
    "rf_param_grid_pipe = {\n",
    "    \"rf__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"rf__max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
    "    \"rf__max_features\": [None,4,5,6,9,10],\n",
    "    \"rf__min_samples_split\": [2, 5, 10],\n",
    "    \"rf__min_samples_leaf\" : [1, 2, 3, 5, 6],\n",
    "    \"rf__n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanstiate the gridsearch pipeline\n",
    "grid_search_pipe = GridSearchCV(pipeline2, rf_param_grid_pipe, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5940 candidates, totalling 29700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8052 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9952 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12052 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14352 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 16852 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19552 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22452 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 25552 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 28852 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 29700 out of 29700 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rf__criterion': ['gini', 'entropy'],\n",
       "                         'rf__max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 12, 14,\n",
       "                                           16],\n",
       "                         'rf__max_features': [None, 4, 5, 6, 9, 10],\n",
       "                         'rf__min_samples_leaf': [1, 2, 3, 5, 6],\n",
       "                         'rf__min_samples_split': [2, 5, 10],\n",
       "                         'rf__n_estimators': [10, 30, 100]},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the grid search to the data\n",
    "grid_search_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8411110016743819\n",
      "{'rf__criterion': 'gini', 'rf__max_depth': 10, 'rf__max_features': 5, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 10, 'rf__n_estimators': 10}\n",
      "Pipeline(steps=[('ss', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=5,\n",
      "                                        min_samples_leaf=3,\n",
      "                                        min_samples_split=10, n_estimators=10,\n",
      "                                        random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_search_pipe.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_search_pipe.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_search_pipe.best_estimator_)\n",
    "#Identify the best score during fitting with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "#Predictions with grid search\n",
    "#Predict the response for test dataset\n",
    "y_pred = grid_search_pipe.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model F1, how often is the classifier correct?\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling the best Estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle list object\n",
    " \n",
    "model_pickle_path = 'best_model.pkl'\n",
    "\n",
    "#Create a variable to pickle and open it in write mode\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(grid_search_pipe.best_estimator_, model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search\n",
    "\n",
    "Randomized Search allows us to search a distribution for each parameter instead of only a desginated value like GridSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.195254015709299, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Load in the Iris Dataset and the LogisticRegression class\n",
    "iris = load_iris()\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "# Set a distribution and options for the different parameters\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "#Fit and check the best parameters\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(iris.data, iris.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
